{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":7974392,"sourceType":"datasetVersion","datasetId":4692734}],"dockerImageVersionId":30674,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport tensorflow as tf\nfrom sklearn.model_selection import train_test_split\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\nfrom tensorflow.keras.applications import VGG16, ResNet50, EfficientNetB3\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Flatten, Dense, Dropout\nfrom tensorflow.keras.optimizers import Adam","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-03-29T12:52:53.926155Z","iopub.execute_input":"2024-03-29T12:52:53.926702Z","iopub.status.idle":"2024-03-29T12:53:06.865362Z","shell.execute_reply.started":"2024-03-29T12:52:53.926671Z","shell.execute_reply":"2024-03-29T12:53:06.864603Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stderr","text":"2024-03-29 12:52:56.329538: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n2024-03-29 12:52:56.329650: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n2024-03-29 12:52:56.441315: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","output_type":"stream"}]},{"cell_type":"code","source":"import os\nimport pandas as pd\nfrom PIL import Image\nimport numpy as np\nfrom tqdm import tqdm\nimport cv2","metadata":{"execution":{"iopub.status.busy":"2024-03-29T12:53:31.816735Z","iopub.execute_input":"2024-03-29T12:53:31.817894Z","iopub.status.idle":"2024-03-29T12:53:32.014169Z","shell.execute_reply.started":"2024-03-29T12:53:31.817859Z","shell.execute_reply":"2024-03-29T12:53:32.013395Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"train_df = pd.read_csv('/kaggle/input/vista-codefest-1/dataset/train.csv')\nbbox_df = pd.read_csv('/kaggle/input/vista-codefest-1/dataset/bbox.csv')","metadata":{"execution":{"iopub.status.busy":"2024-03-29T12:54:24.800156Z","iopub.execute_input":"2024-03-29T12:54:24.800785Z","iopub.status.idle":"2024-03-29T12:54:24.918217Z","shell.execute_reply.started":"2024-03-29T12:54:24.800753Z","shell.execute_reply":"2024-03-29T12:54:24.917282Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"def preprocess_images(image_folder, output_folder, df, size=(224, 224)):\n    if not os.path.exists(output_folder):\n        os.makedirs(output_folder)\n\n    for i, row in tqdm(df.iterrows(), total=len(df)):\n        image_path = os.path.join(image_folder, row['Name'])\n        image = Image.open(image_path)\n        image = image.resize(size)\n        image = np.array(image)\n\n        # Check if the image has three dimensions (color channels)\n        if len(image.shape) == 3:\n            # Apply histogram equalization\n            for channel in range(image.shape[2]):\n                image[:, :, channel] = cv2.equalizeHist(image[:, :, channel])\n\n            # Apply Gaussian blurring\n            image = cv2.GaussianBlur(image, (5, 5), 0)\n\n        image = image / 255.0  # Normalize pixel values\n        image = (image * 255).astype(np.uint8)  # Convert back to 8-bit values\n\n        output_path = os.path.join(output_folder, row['Name'])\n        cv2.imwrite(output_path, cv2.cvtColor(image, cv2.COLOR_RGB2BGR))\n\n\n\n# Preprocess training images\npreprocess_images('/kaggle/input/vista-codefest-1/dataset/train', '/kaggle/working/dataset/preprocessed/train', train_df)\n\n# Preprocess testing images (assuming you have a test.csv similar to train.csv)\ntest_df = pd.read_csv('/kaggle/input/vista-codefest-1/dataset/test.csv')\npreprocess_images('/kaggle/input/vista-codefest-1/dataset/test', '/kaggle/working/dataset/preprocessed/test', test_df)\n\n","metadata":{"execution":{"iopub.status.busy":"2024-03-29T13:01:03.818620Z","iopub.execute_input":"2024-03-29T13:01:03.819470Z","iopub.status.idle":"2024-03-29T13:04:44.862701Z","shell.execute_reply.started":"2024-03-29T13:01:03.819437Z","shell.execute_reply":"2024-03-29T13:04:44.861765Z"},"trusted":true},"execution_count":6,"outputs":[{"name":"stderr","text":"100%|██████████| 10233/10233 [02:34<00:00, 66.31it/s]\n100%|██████████| 3963/3963 [01:06<00:00, 59.43it/s]\n","output_type":"stream"}]},{"cell_type":"code","source":"def process_bounding_boxes(df, image_folder):\n    processed_boxes = {}\n    for _, row in tqdm(df.iterrows(), total=len(df)):\n        image_name = row['Name']\n        if image_name not in processed_boxes:\n            processed_boxes[image_name] = []\n        processed_boxes[image_name].append([row['xmin'], row['ymin'], row['xmax'], row['ymax']])\n\n    # Save or use the processed_boxes dictionary as needed\n    return processed_boxes\n\nbbox_dict = process_bounding_boxes(bbox_df, '/kaggle/input/vista-codefest-1/dataset/train')\n","metadata":{"execution":{"iopub.status.busy":"2024-03-29T13:05:05.120100Z","iopub.execute_input":"2024-03-29T13:05:05.120492Z","iopub.status.idle":"2024-03-29T13:05:09.868509Z","shell.execute_reply.started":"2024-03-29T13:05:05.120458Z","shell.execute_reply":"2024-03-29T13:05:09.867626Z"},"trusted":true},"execution_count":7,"outputs":[{"name":"stderr","text":"100%|██████████| 62529/62529 [00:04<00:00, 13201.20it/s]\n","output_type":"stream"}]},{"cell_type":"code","source":"# Load the preprocessed data\ntrain_df = pd.read_csv('/kaggle/input/vista-codefest-1/dataset/train.csv')\ntrain_df['HeadCount'] = train_df['HeadCount'].astype('float32')\ntest_df = pd.read_csv('/kaggle/input/vista-codefest-1/dataset/test.csv')\ntest_df['HeadCount'] = test_df['HeadCount'].astype('float32')\n\n# Split the data into training and validation sets\ntrain_data, val_data = train_test_split(train_df, test_size=0.2, random_state=42)\n\n\n# Set up image data generators with data augmentation\ntrain_datagen = ImageDataGenerator(\n    rescale=1./255,\n    rotation_range=20,\n    width_shift_range=0.2,\n    height_shift_range=0.2,\n    shear_range=0.2,\n    zoom_range=0.2,\n    horizontal_flip=True,\n    fill_mode='nearest'\n)\n\nval_datagen = ImageDataGenerator(rescale=1./255)\n\n# Create data generators\ntrain_generator = train_datagen.flow_from_dataframe(\n    dataframe=train_data,\n    directory='/kaggle/working/dataset/preprocessed/train',\n    x_col='Name',\n    y_col='HeadCount',\n    target_size=(224, 224),\n    batch_size=32,\n    class_mode='raw'\n)\n\nval_generator = val_datagen.flow_from_dataframe(\n    dataframe=val_data,\n    directory='/kaggle/working/dataset/preprocessed/train',\n    x_col='Name',\n    y_col='HeadCount',\n    target_size=(224, 224),\n    batch_size=32,\n    class_mode='raw'\n)","metadata":{"execution":{"iopub.status.busy":"2024-03-29T15:01:52.961689Z","iopub.execute_input":"2024-03-29T15:01:52.962060Z","iopub.status.idle":"2024-03-29T15:01:53.098676Z","shell.execute_reply.started":"2024-03-29T15:01:52.962029Z","shell.execute_reply":"2024-03-29T15:01:53.097874Z"},"trusted":true},"execution_count":27,"outputs":[{"name":"stdout","text":"Found 8186 validated image filenames.\nFound 2047 validated image filenames.\n","output_type":"stream"}]},{"cell_type":"code","source":"from tensorflow.keras.applications import EfficientNetB3\n\n# Define the create_model function\ndef create_model(base_model):\n    model = Sequential()\n    model.add(base_model)\n    model.add(Flatten())\n    model.add(Dense(256, activation='relu'))\n    model.add(Dropout(0.5))\n    model.add(Dense(1, activation='linear'))\n    model.compile(optimizer=Adam(learning_rate=1e-4), loss='mse', metrics=[tf.keras.metrics.RootMeanSquaredError(name='rmse')])\n    return model\n\n# EfficientNetB3 model\nefficientnet_base = EfficientNetB3(weights='imagenet', include_top=False, input_shape=(224, 224, 3))\nefficientnet_model = create_model(efficientnet_base)\nefficientnet_model.fit(train_generator, epochs=15, validation_data=val_generator)","metadata":{"execution":{"iopub.status.busy":"2024-03-29T15:02:29.873316Z","iopub.execute_input":"2024-03-29T15:02:29.873977Z","iopub.status.idle":"2024-03-29T15:34:06.878315Z","shell.execute_reply.started":"2024-03-29T15:02:29.873943Z","shell.execute_reply":"2024-03-29T15:34:06.877393Z"},"trusted":true},"execution_count":29,"outputs":[{"name":"stdout","text":"Epoch 1/15\n","output_type":"stream"},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:122: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n  self._warn_if_super_not_called()\n","output_type":"stream"},{"name":"stdout","text":"\u001b[1m256/256\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m395s\u001b[0m 904ms/step - loss: 16.0921 - rmse: 3.9705 - val_loss: 28.8995 - val_rmse: 5.3757\nEpoch 2/15\n\u001b[1m256/256\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m107s\u001b[0m 405ms/step - loss: 9.3873 - rmse: 3.0614 - val_loss: 24.6603 - val_rmse: 4.9661\nEpoch 3/15\n\u001b[1m256/256\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m107s\u001b[0m 407ms/step - loss: 9.0444 - rmse: 3.0064 - val_loss: 7.5891 - val_rmse: 2.7549\nEpoch 4/15\n\u001b[1m256/256\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m107s\u001b[0m 406ms/step - loss: 7.6963 - rmse: 2.7735 - val_loss: 7.1093 - val_rmse: 2.6663\nEpoch 5/15\n\u001b[1m256/256\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m106s\u001b[0m 403ms/step - loss: 7.2534 - rmse: 2.6919 - val_loss: 6.8966 - val_rmse: 2.6261\nEpoch 6/15\n\u001b[1m256/256\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m107s\u001b[0m 405ms/step - loss: 6.8675 - rmse: 2.6199 - val_loss: 6.1652 - val_rmse: 2.4828\nEpoch 7/15\n\u001b[1m256/256\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m106s\u001b[0m 404ms/step - loss: 6.5522 - rmse: 2.5593 - val_loss: 5.9470 - val_rmse: 2.4385\nEpoch 8/15\n\u001b[1m256/256\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m109s\u001b[0m 414ms/step - loss: 6.2176 - rmse: 2.4902 - val_loss: 6.1148 - val_rmse: 2.4723\nEpoch 9/15\n\u001b[1m256/256\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m108s\u001b[0m 410ms/step - loss: 6.4263 - rmse: 2.5334 - val_loss: 6.2892 - val_rmse: 2.5079\nEpoch 10/15\n\u001b[1m256/256\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m107s\u001b[0m 405ms/step - loss: 6.0561 - rmse: 2.4589 - val_loss: 6.2005 - val_rmse: 2.4900\nEpoch 11/15\n\u001b[1m256/256\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m108s\u001b[0m 411ms/step - loss: 5.5280 - rmse: 2.3502 - val_loss: 5.8913 - val_rmse: 2.4274\nEpoch 12/15\n\u001b[1m256/256\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m107s\u001b[0m 405ms/step - loss: 5.1812 - rmse: 2.2743 - val_loss: 6.2260 - val_rmse: 2.4952\nEpoch 13/15\n\u001b[1m256/256\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m107s\u001b[0m 406ms/step - loss: 5.9919 - rmse: 2.4459 - val_loss: 5.5553 - val_rmse: 2.3572\nEpoch 14/15\n\u001b[1m256/256\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m108s\u001b[0m 409ms/step - loss: 7.0150 - rmse: 2.6254 - val_loss: 5.8141 - val_rmse: 2.4112\nEpoch 15/15\n\u001b[1m256/256\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m107s\u001b[0m 407ms/step - loss: 5.6715 - rmse: 2.3793 - val_loss: 5.9274 - val_rmse: 2.4347\n","output_type":"stream"},{"execution_count":29,"output_type":"execute_result","data":{"text/plain":"<keras.src.callbacks.history.History at 0x7d6b7634ab60>"},"metadata":{}}]},{"cell_type":"code","source":"# Assume 'test_generator' is already created similar to 'train_generator' but without shuffling\ntest_generator = test_datagen.flow_from_dataframe(\n    dataframe=test_df,\n    directory='/kaggle/working/dataset/preprocessed/test',\n    x_col='Name',\n    target_size=(224, 224),\n    batch_size=32,\n    class_mode=None,\n    shuffle=False\n)\n\n# Make predictions on the test set\npredictions = efficientnet_model.predict(test_generator)\n\n# Prepare submission DataFrame\nsubmission_df = pd.DataFrame({\n    'Name': test_df['Name'],\n    'HeadCount': predictions.flatten()\n})\n\n# Save to CSV\nsubmission_df.to_csv('/kaggle/working/submission_efficientnet_optimized.csv', index=False)\n","metadata":{"execution":{"iopub.status.busy":"2024-03-29T15:34:06.880038Z","iopub.execute_input":"2024-03-29T15:34:06.880331Z","iopub.status.idle":"2024-03-29T15:34:32.681958Z","shell.execute_reply.started":"2024-03-29T15:34:06.880306Z","shell.execute_reply":"2024-03-29T15:34:32.680836Z"},"trusted":true},"execution_count":30,"outputs":[{"name":"stdout","text":"Found 3963 validated image filenames.\n\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 144ms/step\n","output_type":"stream"}]},{"cell_type":"code","source":"def create_model_finetuned(base_model, unfreeze_layers):\n    # Unfreeze the top layers\n    base_model.trainable = True\n    for layer in base_model.layers[:-unfreeze_layers]:\n        layer.trainable = False\n\n    model = Sequential()\n    model.add(base_model)\n    model.add(Flatten())\n    model.add(Dense(256, activation='relu'))\n    model.add(Dropout(0.5))\n    model.add(Dense(1, activation='linear'))\n    model.compile(optimizer=Adam(learning_rate=1e-5), loss='mse', metrics=[tf.keras.metrics.RootMeanSquaredError(name='rmse')])\n    return model\n\n# Create and train a fine-tuned model\nefficientnet_model_finetuned = create_model_finetuned(efficientnet_base, unfreeze_layers=20)\nefficientnet_model_finetuned.fit(train_generator, epochs=15, validation_data=val_generator)","metadata":{"execution":{"iopub.status.busy":"2024-03-29T15:34:32.683276Z","iopub.execute_input":"2024-03-29T15:34:32.683632Z","iopub.status.idle":"2024-03-29T16:03:08.639180Z","shell.execute_reply.started":"2024-03-29T15:34:32.683602Z","shell.execute_reply":"2024-03-29T16:03:08.638336Z"},"trusted":true},"execution_count":31,"outputs":[{"name":"stdout","text":"Epoch 1/15\n\u001b[1m256/256\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m214s\u001b[0m 599ms/step - loss: 11.4016 - rmse: 3.2934 - val_loss: 5.6454 - val_rmse: 2.3759\nEpoch 2/15\n\u001b[1m256/256\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m104s\u001b[0m 395ms/step - loss: 4.4581 - rmse: 2.1104 - val_loss: 5.4770 - val_rmse: 2.3402\nEpoch 3/15\n\u001b[1m256/256\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m106s\u001b[0m 401ms/step - loss: 5.2144 - rmse: 2.2760 - val_loss: 5.3753 - val_rmse: 2.3188\nEpoch 4/15\n\u001b[1m256/256\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m104s\u001b[0m 398ms/step - loss: 3.9976 - rmse: 1.9981 - val_loss: 5.5804 - val_rmse: 2.3625\nEpoch 5/15\n\u001b[1m256/256\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m104s\u001b[0m 396ms/step - loss: 4.5106 - rmse: 2.1211 - val_loss: 5.5653 - val_rmse: 2.3584\nEpoch 6/15\n\u001b[1m256/256\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m106s\u001b[0m 403ms/step - loss: 4.8272 - rmse: 2.1909 - val_loss: 5.3381 - val_rmse: 2.3103\nEpoch 7/15\n\u001b[1m256/256\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m104s\u001b[0m 396ms/step - loss: 4.1630 - rmse: 2.0394 - val_loss: 5.2719 - val_rmse: 2.2959\nEpoch 8/15\n\u001b[1m256/256\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m104s\u001b[0m 395ms/step - loss: 4.4449 - rmse: 2.1054 - val_loss: 5.2328 - val_rmse: 2.2876\nEpoch 9/15\n\u001b[1m256/256\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m143s\u001b[0m 399ms/step - loss: 4.0213 - rmse: 2.0051 - val_loss: 5.3839 - val_rmse: 2.3206\nEpoch 10/15\n\u001b[1m256/256\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m104s\u001b[0m 397ms/step - loss: 3.8766 - rmse: 1.9684 - val_loss: 5.2334 - val_rmse: 2.2873\nEpoch 11/15\n\u001b[1m256/256\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m104s\u001b[0m 397ms/step - loss: 3.8360 - rmse: 1.9560 - val_loss: 5.3230 - val_rmse: 2.3071\nEpoch 12/15\n\u001b[1m256/256\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m105s\u001b[0m 399ms/step - loss: 4.0794 - rmse: 2.0167 - val_loss: 5.2705 - val_rmse: 2.2950\nEpoch 13/15\n\u001b[1m256/256\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m104s\u001b[0m 395ms/step - loss: 3.5978 - rmse: 1.8960 - val_loss: 5.2521 - val_rmse: 2.2917\nEpoch 14/15\n\u001b[1m256/256\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m104s\u001b[0m 394ms/step - loss: 4.6079 - rmse: 2.1272 - val_loss: 5.1825 - val_rmse: 2.2765\nEpoch 15/15\n\u001b[1m256/256\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m105s\u001b[0m 398ms/step - loss: 3.8415 - rmse: 1.9589 - val_loss: 5.2072 - val_rmse: 2.2821\n","output_type":"stream"},{"execution_count":31,"output_type":"execute_result","data":{"text/plain":"<keras.src.callbacks.history.History at 0x7d677c3e5630>"},"metadata":{}}]},{"cell_type":"code","source":"# Assume 'test_generator' is already created similar to 'train_generator' but without shuffling\ntest_generator = test_datagen.flow_from_dataframe(\n    dataframe=test_df,\n    directory='/kaggle/working/dataset/preprocessed/test',\n    x_col='Name',\n    target_size=(224, 224),\n    batch_size=32,\n    class_mode=None,\n    shuffle=False\n)\n\n# Make predictions on the test set\npredictions = efficientnet_model_finetuned.predict(test_generator)\n\n# Prepare submission DataFrame\nsubmission_df = pd.DataFrame({\n    'Name': test_df['Name'],\n    'HeadCount': predictions.flatten()\n})\n\n# Save to CSV\nsubmission_df.to_csv('/kaggle/working/submission_efficientnet_finetuned_optimized.csv', index=False)","metadata":{"execution":{"iopub.status.busy":"2024-03-29T16:11:39.792738Z","iopub.execute_input":"2024-03-29T16:11:39.793690Z","iopub.status.idle":"2024-03-29T16:11:45.513157Z","shell.execute_reply.started":"2024-03-29T16:11:39.793656Z","shell.execute_reply":"2024-03-29T16:11:45.512389Z"},"trusted":true},"execution_count":34,"outputs":[{"name":"stdout","text":"Found 3963 validated image filenames.\n\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 44ms/step\n","output_type":"stream"}]},{"cell_type":"code","source":"def create_custom_model(base_model):\n    model = Sequential()\n    model.add(base_model)\n    model.add(Flatten())\n    model.add(Dense(512, activation='relu'))\n    model.add(Dropout(0.5))\n    model.add(Dense(256, activation='relu'))\n    model.add(Dropout(0.3))\n    model.add(Dense(1, activation='linear'))\n    model.compile(optimizer=Adam(learning_rate=1e-4), loss='mse', metrics=[tf.keras.metrics.RootMeanSquaredError(name='rmse')])\n    return model\n\n# Create and train a custom model\ncustom_model = create_custom_model(efficientnet_base)\ncustom_model.fit(train_generator, epochs=15, validation_data=val_generator)","metadata":{"execution":{"iopub.status.busy":"2024-03-29T16:11:45.514587Z","iopub.execute_input":"2024-03-29T16:11:45.514872Z","iopub.status.idle":"2024-03-29T16:39:36.268803Z","shell.execute_reply.started":"2024-03-29T16:11:45.514846Z","shell.execute_reply":"2024-03-29T16:39:36.267857Z"},"trusted":true},"execution_count":35,"outputs":[{"name":"stdout","text":"Epoch 1/15\n\u001b[1m256/256\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m216s\u001b[0m 607ms/step - loss: 9.0494 - rmse: 2.9449 - val_loss: 6.1436 - val_rmse: 2.4781\nEpoch 2/15\n\u001b[1m256/256\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m104s\u001b[0m 395ms/step - loss: 5.1918 - rmse: 2.2751 - val_loss: 6.3937 - val_rmse: 2.5287\nEpoch 3/15\n\u001b[1m256/256\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m104s\u001b[0m 393ms/step - loss: 5.1926 - rmse: 2.2784 - val_loss: 8.7455 - val_rmse: 2.9575\nEpoch 4/15\n\u001b[1m256/256\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m104s\u001b[0m 397ms/step - loss: 4.7991 - rmse: 2.1900 - val_loss: 12.8431 - val_rmse: 3.5839\nEpoch 5/15\n\u001b[1m256/256\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m106s\u001b[0m 402ms/step - loss: 4.8138 - rmse: 2.1932 - val_loss: 8.9895 - val_rmse: 2.9986\nEpoch 6/15\n\u001b[1m256/256\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m104s\u001b[0m 394ms/step - loss: 4.2891 - rmse: 2.0696 - val_loss: 8.5042 - val_rmse: 2.9161\nEpoch 7/15\n\u001b[1m256/256\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m103s\u001b[0m 393ms/step - loss: 4.5805 - rmse: 2.1395 - val_loss: 10.6101 - val_rmse: 3.2573\nEpoch 8/15\n\u001b[1m256/256\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m104s\u001b[0m 395ms/step - loss: 4.3474 - rmse: 2.0809 - val_loss: 11.4575 - val_rmse: 3.3847\nEpoch 9/15\n\u001b[1m256/256\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m104s\u001b[0m 395ms/step - loss: 4.4015 - rmse: 2.0972 - val_loss: 12.0167 - val_rmse: 3.4662\nEpoch 10/15\n\u001b[1m256/256\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m104s\u001b[0m 395ms/step - loss: 4.2934 - rmse: 2.0718 - val_loss: 12.1505 - val_rmse: 3.4856\nEpoch 11/15\n\u001b[1m256/256\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m104s\u001b[0m 395ms/step - loss: 4.0027 - rmse: 2.0003 - val_loss: 14.2261 - val_rmse: 3.7720\nEpoch 12/15\n\u001b[1m256/256\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m103s\u001b[0m 393ms/step - loss: 4.0684 - rmse: 2.0155 - val_loss: 11.3392 - val_rmse: 3.3674\nEpoch 13/15\n\u001b[1m256/256\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m103s\u001b[0m 392ms/step - loss: 3.8194 - rmse: 1.9526 - val_loss: 12.7622 - val_rmse: 3.5724\nEpoch 14/15\n\u001b[1m256/256\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m103s\u001b[0m 393ms/step - loss: 4.4286 - rmse: 2.1027 - val_loss: 12.3962 - val_rmse: 3.5209\nEpoch 15/15\n\u001b[1m256/256\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m104s\u001b[0m 395ms/step - loss: 4.3526 - rmse: 2.0816 - val_loss: 11.5109 - val_rmse: 3.3931\n","output_type":"stream"},{"execution_count":35,"output_type":"execute_result","data":{"text/plain":"<keras.src.callbacks.history.History at 0x7d66e5477d30>"},"metadata":{}}]},{"cell_type":"code","source":"# Make predictions with the EfficientNet model\nefficientnet_predictions = efficientnet_model.predict(test_generator)\n\n# Ensemble predictions from VGG16, ResNet50, and EfficientNet\n#ensemble_predictions = (vgg_predictions.flatten() + resnet_predictions.flatten() + efficientnet_predictions.flatten()) / 3\nensemble_predictions = efficientnet_predictions.flatten()\n\n# Round the ensemble predictions to the nearest integer\nensemble_head_counts = ensemble_predictions\n\n# Create a submission DataFrame for the ensemble\nensemble_submission_df = pd.DataFrame({\n    'Name': test_df['Name'],\n    'HeadCount': ensemble_head_counts\n})\n\n# Save the ensemble submission DataFrame to a CSV file\nensemble_submission_df.to_csv('/kaggle/working/ensemble_submission.csv', index=False)","metadata":{"execution":{"iopub.status.busy":"2024-03-29T16:39:36.270290Z","iopub.execute_input":"2024-03-29T16:39:36.270604Z","iopub.status.idle":"2024-03-29T16:39:41.955939Z","shell.execute_reply.started":"2024-03-29T16:39:36.270578Z","shell.execute_reply":"2024-03-29T16:39:41.955036Z"},"trusted":true},"execution_count":36,"outputs":[{"name":"stdout","text":"\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 45ms/step\n","output_type":"stream"}]},{"cell_type":"code","source":"import tensorflow as tf\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\nfrom tensorflow.keras.applications import VGG16\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Flatten, Dense\nfrom tensorflow.keras.optimizers import Adam\nfrom sklearn.model_selection import train_test_split\nimport pandas as pd\n","metadata":{"execution":{"iopub.status.busy":"2024-03-29T16:42:38.681793Z","iopub.execute_input":"2024-03-29T16:42:38.682175Z","iopub.status.idle":"2024-03-29T16:42:38.688031Z","shell.execute_reply.started":"2024-03-29T16:42:38.682143Z","shell.execute_reply":"2024-03-29T16:42:38.686942Z"},"trusted":true},"execution_count":37,"outputs":[]},{"cell_type":"code","source":"train_df = pd.read_csv('/kaggle/input/vista-codefest-1/dataset/train.csv')\ntrain_df['HeadCount'] = train_df['HeadCount'].astype('float32')\ntest_df = pd.read_csv('/kaggle/input/vista-codefest-1/dataset/test.csv')\ntest_df['HeadCount'] = test_df['HeadCount'].astype('float32')\n\n# Split the data into training and validation sets\ntrain_data, val_data = train_test_split(train_df, test_size=0.2, random_state=42)\n\n# Set up image data generators with data augmentation\ntrain_datagen = ImageDataGenerator(\n    rescale=1./255,\n    rotation_range=20,\n    width_shift_range=0.2,\n    height_shift_range=0.2,\n    shear_range=0.2,\n    zoom_range=0.2,\n    horizontal_flip=True,\n    fill_mode='nearest'\n)\n\nval_datagen = ImageDataGenerator(rescale=1./255)\n\n# Create data generators\ntrain_generator = train_datagen.flow_from_dataframe(\n    dataframe=train_data,\n    directory='/kaggle/working/dataset/preprocessed/train',\n    x_col='Name',\n    y_col='HeadCount',\n    target_size=(224, 224),\n    batch_size=32,\n    class_mode='raw'\n)\n\nval_generator = val_datagen.flow_from_dataframe(\n    dataframe=val_data,\n    directory='/kaggle/working/dataset/preprocessed/train',\n    x_col='Name',\n    y_col='HeadCount',\n    target_size=(224, 224),\n    batch_size=32,\n    class_mode='raw'\n)\n","metadata":{"execution":{"iopub.status.busy":"2024-03-29T16:47:23.316702Z","iopub.execute_input":"2024-03-29T16:47:23.317377Z","iopub.status.idle":"2024-03-29T16:47:23.448496Z","shell.execute_reply.started":"2024-03-29T16:47:23.317337Z","shell.execute_reply":"2024-03-29T16:47:23.447733Z"},"trusted":true},"execution_count":42,"outputs":[{"name":"stdout","text":"Found 8186 validated image filenames.\nFound 2047 validated image filenames.\n","output_type":"stream"}]},{"cell_type":"code","source":"from tensorflow.keras.applications import VGG16\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Flatten, Dense\nfrom tensorflow.keras.optimizers import Adam\nimport tensorflow as tf\n\n# Load a pre-trained VGG16 model without the top layer\nbase_model = VGG16(weights='imagenet', include_top=False, input_shape=(224, 224, 3))\n\n# Freeze the base model layers\nfor layer in base_model.layers:\n    layer.trainable = False\n\n# Create a sequential model and add the base model\nmodel = Sequential()\nmodel.add(base_model)\nmodel.add(Flatten())\nmodel.add(Dense(256, activation='relu'))\nmodel.add(Dense(1, activation='linear'))  # Output layer for regression\n\n# Compile the model\nmodel.compile(optimizer=Adam(learning_rate=1e-4), loss='mse', metrics=[tf.keras.metrics.RootMeanSquaredError(name='rmse')])\n","metadata":{"execution":{"iopub.status.busy":"2024-03-29T16:47:26.952849Z","iopub.execute_input":"2024-03-29T16:47:26.953281Z","iopub.status.idle":"2024-03-29T16:47:27.215209Z","shell.execute_reply.started":"2024-03-29T16:47:26.953247Z","shell.execute_reply":"2024-03-29T16:47:27.214395Z"},"trusted":true},"execution_count":43,"outputs":[]},{"cell_type":"code","source":"history = model.fit(\n    train_generator,\n    epochs=10,\n    validation_data=val_generator\n)\n","metadata":{"execution":{"iopub.status.busy":"2024-03-29T16:47:32.518575Z","iopub.execute_input":"2024-03-29T16:47:32.518912Z","iopub.status.idle":"2024-03-29T17:05:42.095593Z","shell.execute_reply.started":"2024-03-29T16:47:32.518886Z","shell.execute_reply":"2024-03-29T17:05:42.094829Z"},"trusted":true},"execution_count":44,"outputs":[{"name":"stdout","text":"Epoch 1/10\n","output_type":"stream"},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:122: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n  self._warn_if_super_not_called()\n2024-03-29 16:47:38.471454: E external/local_xla/xla/service/gpu/buffer_comparator.cc:1137] Difference at 0: 4.63498, expected 3.85968\n2024-03-29 16:47:38.471506: E external/local_xla/xla/service/gpu/buffer_comparator.cc:1137] Difference at 3: 6.55784, expected 5.78254\n2024-03-29 16:47:38.471515: E external/local_xla/xla/service/gpu/buffer_comparator.cc:1137] Difference at 4: 6.61282, expected 5.83752\n2024-03-29 16:47:38.471523: E external/local_xla/xla/service/gpu/buffer_comparator.cc:1137] Difference at 6: 6.34499, expected 5.56968\n2024-03-29 16:47:38.471531: E external/local_xla/xla/service/gpu/buffer_comparator.cc:1137] Difference at 7: 6.25159, expected 5.47629\n2024-03-29 16:47:38.471538: E external/local_xla/xla/service/gpu/buffer_comparator.cc:1137] Difference at 8: 5.43964, expected 4.66434\n2024-03-29 16:47:38.471546: E external/local_xla/xla/service/gpu/buffer_comparator.cc:1137] Difference at 9: 6.54333, expected 5.76803\n2024-03-29 16:47:38.471553: E external/local_xla/xla/service/gpu/buffer_comparator.cc:1137] Difference at 10: 5.76049, expected 4.98519\n2024-03-29 16:47:38.471561: E external/local_xla/xla/service/gpu/buffer_comparator.cc:1137] Difference at 11: 5.33632, expected 4.56101\n2024-03-29 16:47:38.471568: E external/local_xla/xla/service/gpu/buffer_comparator.cc:1137] Difference at 12: 4.04081, expected 3.2655\n2024-03-29 16:47:38.518814: E external/local_xla/xla/service/gpu/conv_algorithm_picker.cc:705] Results mismatch between different convolution algorithms. This is likely a bug/unexpected loss of precision in cudnn.\n(f32[32,64,224,224]{3,2,1,0}, u8[0]{0}) custom-call(f32[32,3,224,224]{3,2,1,0}, f32[64,3,3,3]{3,2,1,0}, f32[64]{0}), window={size=3x3 pad=1_1x1_1}, dim_labels=bf01_oi01->bf01, custom_call_target=\"__cudnn$convBiasActivationForward\", backend_config={\"conv_result_scale\":1,\"activation_mode\":\"kRelu\",\"side_input_scale\":0,\"leakyrelu_alpha\":0} for eng20{k2=1,k4=1,k5=1,k6=0,k7=0} vs eng15{k5=1,k6=0,k7=1,k10=1}\n2024-03-29 16:47:38.518856: E external/local_xla/xla/service/gpu/conv_algorithm_picker.cc:270] Device: Tesla P100-PCIE-16GB\n2024-03-29 16:47:38.518865: E external/local_xla/xla/service/gpu/conv_algorithm_picker.cc:271] Platform: Compute Capability 6.0\n2024-03-29 16:47:38.518872: E external/local_xla/xla/service/gpu/conv_algorithm_picker.cc:272] Driver: 12020 (535.129.3)\n2024-03-29 16:47:38.518880: E external/local_xla/xla/service/gpu/conv_algorithm_picker.cc:273] Runtime: <undefined>\n2024-03-29 16:47:38.518898: E external/local_xla/xla/service/gpu/conv_algorithm_picker.cc:280] cudnn version: 8.9.0\n2024-03-29 16:47:39.608071: E external/local_xla/xla/service/gpu/buffer_comparator.cc:1137] Difference at 0: 4.63498, expected 3.85968\n2024-03-29 16:47:39.608125: E external/local_xla/xla/service/gpu/buffer_comparator.cc:1137] Difference at 3: 6.55784, expected 5.78254\n2024-03-29 16:47:39.608140: E external/local_xla/xla/service/gpu/buffer_comparator.cc:1137] Difference at 4: 6.61282, expected 5.83752\n2024-03-29 16:47:39.608151: E external/local_xla/xla/service/gpu/buffer_comparator.cc:1137] Difference at 6: 6.34499, expected 5.56968\n2024-03-29 16:47:39.608164: E external/local_xla/xla/service/gpu/buffer_comparator.cc:1137] Difference at 7: 6.25159, expected 5.47629\n2024-03-29 16:47:39.608178: E external/local_xla/xla/service/gpu/buffer_comparator.cc:1137] Difference at 8: 5.43964, expected 4.66434\n2024-03-29 16:47:39.608190: E external/local_xla/xla/service/gpu/buffer_comparator.cc:1137] Difference at 9: 6.54333, expected 5.76803\n2024-03-29 16:47:39.608201: E external/local_xla/xla/service/gpu/buffer_comparator.cc:1137] Difference at 10: 5.76049, expected 4.98519\n2024-03-29 16:47:39.608214: E external/local_xla/xla/service/gpu/buffer_comparator.cc:1137] Difference at 11: 5.33632, expected 4.56101\n2024-03-29 16:47:39.608225: E external/local_xla/xla/service/gpu/buffer_comparator.cc:1137] Difference at 12: 4.04081, expected 3.2655\n2024-03-29 16:47:39.657366: E external/local_xla/xla/service/gpu/conv_algorithm_picker.cc:705] Results mismatch between different convolution algorithms. This is likely a bug/unexpected loss of precision in cudnn.\n(f32[32,64,224,224]{3,2,1,0}, u8[0]{0}) custom-call(f32[32,3,224,224]{3,2,1,0}, f32[64,3,3,3]{3,2,1,0}, f32[64]{0}), window={size=3x3 pad=1_1x1_1}, dim_labels=bf01_oi01->bf01, custom_call_target=\"__cudnn$convBiasActivationForward\", backend_config={\"conv_result_scale\":1,\"activation_mode\":\"kRelu\",\"side_input_scale\":0,\"leakyrelu_alpha\":0} for eng20{k2=1,k4=1,k5=1,k6=0,k7=0} vs eng15{k5=1,k6=0,k7=1,k10=1}\n2024-03-29 16:47:39.657421: E external/local_xla/xla/service/gpu/conv_algorithm_picker.cc:270] Device: Tesla P100-PCIE-16GB\n2024-03-29 16:47:39.657430: E external/local_xla/xla/service/gpu/conv_algorithm_picker.cc:271] Platform: Compute Capability 6.0\n2024-03-29 16:47:39.657437: E external/local_xla/xla/service/gpu/conv_algorithm_picker.cc:272] Driver: 12020 (535.129.3)\n2024-03-29 16:47:39.657444: E external/local_xla/xla/service/gpu/conv_algorithm_picker.cc:273] Runtime: <undefined>\n2024-03-29 16:47:39.657461: E external/local_xla/xla/service/gpu/conv_algorithm_picker.cc:280] cudnn version: 8.9.0\n","output_type":"stream"},{"name":"stdout","text":"\u001b[1m213/256\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m16s\u001b[0m 389ms/step - loss: 15.2929 - rmse: 3.8814","output_type":"stream"},{"name":"stderr","text":"2024-03-29 16:49:17.432254: E external/local_xla/xla/service/gpu/buffer_comparator.cc:1137] Difference at 0: 3.46443, expected 2.59124\n2024-03-29 16:49:17.432307: E external/local_xla/xla/service/gpu/buffer_comparator.cc:1137] Difference at 1: 4.84232, expected 3.96913\n2024-03-29 16:49:17.432316: E external/local_xla/xla/service/gpu/buffer_comparator.cc:1137] Difference at 2: 4.91526, expected 4.04207\n2024-03-29 16:49:17.432324: E external/local_xla/xla/service/gpu/buffer_comparator.cc:1137] Difference at 3: 5.02814, expected 4.15494\n2024-03-29 16:49:17.432331: E external/local_xla/xla/service/gpu/buffer_comparator.cc:1137] Difference at 4: 4.53562, expected 3.66243\n2024-03-29 16:49:17.432339: E external/local_xla/xla/service/gpu/buffer_comparator.cc:1137] Difference at 5: 4.79722, expected 3.92403\n2024-03-29 16:49:17.432358: E external/local_xla/xla/service/gpu/buffer_comparator.cc:1137] Difference at 6: 4.69349, expected 3.82029\n2024-03-29 16:49:17.432366: E external/local_xla/xla/service/gpu/buffer_comparator.cc:1137] Difference at 7: 4.56663, expected 3.69344\n2024-03-29 16:49:17.432373: E external/local_xla/xla/service/gpu/buffer_comparator.cc:1137] Difference at 8: 4.13587, expected 3.26268\n2024-03-29 16:49:17.432381: E external/local_xla/xla/service/gpu/buffer_comparator.cc:1137] Difference at 9: 5.00661, expected 4.13342\n2024-03-29 16:49:17.470801: E external/local_xla/xla/service/gpu/conv_algorithm_picker.cc:705] Results mismatch between different convolution algorithms. This is likely a bug/unexpected loss of precision in cudnn.\n(f32[26,64,224,224]{3,2,1,0}, u8[0]{0}) custom-call(f32[26,3,224,224]{3,2,1,0}, f32[64,3,3,3]{3,2,1,0}, f32[64]{0}), window={size=3x3 pad=1_1x1_1}, dim_labels=bf01_oi01->bf01, custom_call_target=\"__cudnn$convBiasActivationForward\", backend_config={\"conv_result_scale\":1,\"activation_mode\":\"kRelu\",\"side_input_scale\":0,\"leakyrelu_alpha\":0} for eng20{k2=1,k4=1,k5=1,k6=0,k7=0} vs eng15{k5=1,k6=0,k7=1,k10=1}\n2024-03-29 16:49:17.470834: E external/local_xla/xla/service/gpu/conv_algorithm_picker.cc:270] Device: Tesla P100-PCIE-16GB\n2024-03-29 16:49:17.470842: E external/local_xla/xla/service/gpu/conv_algorithm_picker.cc:271] Platform: Compute Capability 6.0\n2024-03-29 16:49:17.470850: E external/local_xla/xla/service/gpu/conv_algorithm_picker.cc:272] Driver: 12020 (535.129.3)\n2024-03-29 16:49:17.470857: E external/local_xla/xla/service/gpu/conv_algorithm_picker.cc:273] Runtime: <undefined>\n2024-03-29 16:49:17.470873: E external/local_xla/xla/service/gpu/conv_algorithm_picker.cc:280] cudnn version: 8.9.0\n2024-03-29 16:49:18.307052: E external/local_xla/xla/service/gpu/buffer_comparator.cc:1137] Difference at 0: 3.46443, expected 2.59124\n2024-03-29 16:49:18.307108: E external/local_xla/xla/service/gpu/buffer_comparator.cc:1137] Difference at 1: 4.84232, expected 3.96913\n2024-03-29 16:49:18.307117: E external/local_xla/xla/service/gpu/buffer_comparator.cc:1137] Difference at 2: 4.91526, expected 4.04207\n2024-03-29 16:49:18.307124: E external/local_xla/xla/service/gpu/buffer_comparator.cc:1137] Difference at 3: 5.02814, expected 4.15494\n2024-03-29 16:49:18.307132: E external/local_xla/xla/service/gpu/buffer_comparator.cc:1137] Difference at 4: 4.53562, expected 3.66243\n2024-03-29 16:49:18.307140: E external/local_xla/xla/service/gpu/buffer_comparator.cc:1137] Difference at 5: 4.79722, expected 3.92403\n2024-03-29 16:49:18.307147: E external/local_xla/xla/service/gpu/buffer_comparator.cc:1137] Difference at 6: 4.69349, expected 3.82029\n2024-03-29 16:49:18.307155: E external/local_xla/xla/service/gpu/buffer_comparator.cc:1137] Difference at 7: 4.56663, expected 3.69344\n2024-03-29 16:49:18.307162: E external/local_xla/xla/service/gpu/buffer_comparator.cc:1137] Difference at 8: 4.13587, expected 3.26268\n2024-03-29 16:49:18.307170: E external/local_xla/xla/service/gpu/buffer_comparator.cc:1137] Difference at 9: 5.00661, expected 4.13342\n2024-03-29 16:49:18.344824: E external/local_xla/xla/service/gpu/conv_algorithm_picker.cc:705] Results mismatch between different convolution algorithms. This is likely a bug/unexpected loss of precision in cudnn.\n(f32[26,64,224,224]{3,2,1,0}, u8[0]{0}) custom-call(f32[26,3,224,224]{3,2,1,0}, f32[64,3,3,3]{3,2,1,0}, f32[64]{0}), window={size=3x3 pad=1_1x1_1}, dim_labels=bf01_oi01->bf01, custom_call_target=\"__cudnn$convBiasActivationForward\", backend_config={\"conv_result_scale\":1,\"activation_mode\":\"kRelu\",\"side_input_scale\":0,\"leakyrelu_alpha\":0} for eng20{k2=1,k4=1,k5=1,k6=0,k7=0} vs eng15{k5=1,k6=0,k7=1,k10=1}\n2024-03-29 16:49:18.344875: E external/local_xla/xla/service/gpu/conv_algorithm_picker.cc:270] Device: Tesla P100-PCIE-16GB\n2024-03-29 16:49:18.344884: E external/local_xla/xla/service/gpu/conv_algorithm_picker.cc:271] Platform: Compute Capability 6.0\n2024-03-29 16:49:18.344891: E external/local_xla/xla/service/gpu/conv_algorithm_picker.cc:272] Driver: 12020 (535.129.3)\n2024-03-29 16:49:18.344898: E external/local_xla/xla/service/gpu/conv_algorithm_picker.cc:273] Runtime: <undefined>\n2024-03-29 16:49:18.344915: E external/local_xla/xla/service/gpu/conv_algorithm_picker.cc:280] cudnn version: 8.9.0\n","output_type":"stream"},{"name":"stdout","text":"\u001b[1m256/256\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 428ms/step - loss: 14.8698 - rmse: 3.8299","output_type":"stream"},{"name":"stderr","text":"2024-03-29 16:49:48.564050: E external/local_xla/xla/service/gpu/buffer_comparator.cc:1137] Difference at 100352: 3.62212, expected 2.70127\n2024-03-29 16:49:48.564100: E external/local_xla/xla/service/gpu/buffer_comparator.cc:1137] Difference at 100353: 5.31563, expected 4.39477\n2024-03-29 16:49:48.564109: E external/local_xla/xla/service/gpu/buffer_comparator.cc:1137] Difference at 100354: 5.43093, expected 4.51007\n2024-03-29 16:49:48.564117: E external/local_xla/xla/service/gpu/buffer_comparator.cc:1137] Difference at 100355: 5.35723, expected 4.43638\n2024-03-29 16:49:48.564124: E external/local_xla/xla/service/gpu/buffer_comparator.cc:1137] Difference at 100356: 5.06878, expected 4.14793\n2024-03-29 16:49:48.564132: E external/local_xla/xla/service/gpu/buffer_comparator.cc:1137] Difference at 100357: 5.791, expected 4.87014\n2024-03-29 16:49:48.564140: E external/local_xla/xla/service/gpu/buffer_comparator.cc:1137] Difference at 100358: 5.23388, expected 4.31303\n2024-03-29 16:49:48.564147: E external/local_xla/xla/service/gpu/buffer_comparator.cc:1137] Difference at 100359: 4.43404, expected 3.51319\n2024-03-29 16:49:48.564155: E external/local_xla/xla/service/gpu/buffer_comparator.cc:1137] Difference at 100360: 4.4017, expected 3.48084\n2024-03-29 16:49:48.564162: E external/local_xla/xla/service/gpu/buffer_comparator.cc:1137] Difference at 100361: 5.48382, expected 4.56296\n2024-03-29 16:49:48.608904: E external/local_xla/xla/service/gpu/conv_algorithm_picker.cc:705] Results mismatch between different convolution algorithms. This is likely a bug/unexpected loss of precision in cudnn.\n(f32[31,64,224,224]{3,2,1,0}, u8[0]{0}) custom-call(f32[31,3,224,224]{3,2,1,0}, f32[64,3,3,3]{3,2,1,0}, f32[64]{0}), window={size=3x3 pad=1_1x1_1}, dim_labels=bf01_oi01->bf01, custom_call_target=\"__cudnn$convBiasActivationForward\", backend_config={\"conv_result_scale\":1,\"activation_mode\":\"kRelu\",\"side_input_scale\":0,\"leakyrelu_alpha\":0} for eng20{k2=1,k4=1,k5=1,k6=0,k7=0} vs eng15{k5=1,k6=0,k7=1,k10=1}\n2024-03-29 16:49:48.608947: E external/local_xla/xla/service/gpu/conv_algorithm_picker.cc:270] Device: Tesla P100-PCIE-16GB\n2024-03-29 16:49:48.608955: E external/local_xla/xla/service/gpu/conv_algorithm_picker.cc:271] Platform: Compute Capability 6.0\n2024-03-29 16:49:48.608962: E external/local_xla/xla/service/gpu/conv_algorithm_picker.cc:272] Driver: 12020 (535.129.3)\n2024-03-29 16:49:48.608969: E external/local_xla/xla/service/gpu/conv_algorithm_picker.cc:273] Runtime: <undefined>\n2024-03-29 16:49:48.608986: E external/local_xla/xla/service/gpu/conv_algorithm_picker.cc:280] cudnn version: 8.9.0\n2024-03-29 16:49:49.579628: E external/local_xla/xla/service/gpu/buffer_comparator.cc:1137] Difference at 100352: 3.62212, expected 2.70127\n2024-03-29 16:49:49.579676: E external/local_xla/xla/service/gpu/buffer_comparator.cc:1137] Difference at 100353: 5.31563, expected 4.39477\n2024-03-29 16:49:49.579685: E external/local_xla/xla/service/gpu/buffer_comparator.cc:1137] Difference at 100354: 5.43093, expected 4.51007\n2024-03-29 16:49:49.579693: E external/local_xla/xla/service/gpu/buffer_comparator.cc:1137] Difference at 100355: 5.35723, expected 4.43638\n2024-03-29 16:49:49.579700: E external/local_xla/xla/service/gpu/buffer_comparator.cc:1137] Difference at 100356: 5.06878, expected 4.14793\n2024-03-29 16:49:49.579708: E external/local_xla/xla/service/gpu/buffer_comparator.cc:1137] Difference at 100357: 5.791, expected 4.87014\n2024-03-29 16:49:49.579716: E external/local_xla/xla/service/gpu/buffer_comparator.cc:1137] Difference at 100358: 5.23388, expected 4.31303\n2024-03-29 16:49:49.579723: E external/local_xla/xla/service/gpu/buffer_comparator.cc:1137] Difference at 100359: 4.43404, expected 3.51319\n2024-03-29 16:49:49.579731: E external/local_xla/xla/service/gpu/buffer_comparator.cc:1137] Difference at 100360: 4.4017, expected 3.48084\n2024-03-29 16:49:49.579738: E external/local_xla/xla/service/gpu/buffer_comparator.cc:1137] Difference at 100361: 5.48382, expected 4.56296\n2024-03-29 16:49:49.636183: E external/local_xla/xla/service/gpu/conv_algorithm_picker.cc:705] Results mismatch between different convolution algorithms. This is likely a bug/unexpected loss of precision in cudnn.\n(f32[31,64,224,224]{3,2,1,0}, u8[0]{0}) custom-call(f32[31,3,224,224]{3,2,1,0}, f32[64,3,3,3]{3,2,1,0}, f32[64]{0}), window={size=3x3 pad=1_1x1_1}, dim_labels=bf01_oi01->bf01, custom_call_target=\"__cudnn$convBiasActivationForward\", backend_config={\"conv_result_scale\":1,\"activation_mode\":\"kRelu\",\"side_input_scale\":0,\"leakyrelu_alpha\":0} for eng20{k2=1,k4=1,k5=1,k6=0,k7=0} vs eng15{k5=1,k6=0,k7=1,k10=1}\n2024-03-29 16:49:49.636232: E external/local_xla/xla/service/gpu/conv_algorithm_picker.cc:270] Device: Tesla P100-PCIE-16GB\n2024-03-29 16:49:49.636241: E external/local_xla/xla/service/gpu/conv_algorithm_picker.cc:271] Platform: Compute Capability 6.0\n2024-03-29 16:49:49.636248: E external/local_xla/xla/service/gpu/conv_algorithm_picker.cc:272] Driver: 12020 (535.129.3)\n2024-03-29 16:49:49.636255: E external/local_xla/xla/service/gpu/conv_algorithm_picker.cc:273] Runtime: <undefined>\n2024-03-29 16:49:49.636271: E external/local_xla/xla/service/gpu/conv_algorithm_picker.cc:280] cudnn version: 8.9.0\n","output_type":"stream"},{"name":"stdout","text":"\u001b[1m256/256\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m149s\u001b[0m 501ms/step - loss: 14.8610 - rmse: 3.8288 - val_loss: 9.3074 - val_rmse: 3.0502\nEpoch 2/10\n\u001b[1m256/256\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m106s\u001b[0m 402ms/step - loss: 10.2421 - rmse: 3.1995 - val_loss: 10.0781 - val_rmse: 3.1746\nEpoch 3/10\n\u001b[1m256/256\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m103s\u001b[0m 393ms/step - loss: 9.5269 - rmse: 3.0832 - val_loss: 8.3703 - val_rmse: 2.8932\nEpoch 4/10\n\u001b[1m256/256\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m106s\u001b[0m 404ms/step - loss: 9.7840 - rmse: 3.1270 - val_loss: 9.4452 - val_rmse: 3.0732\nEpoch 5/10\n\u001b[1m256/256\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m104s\u001b[0m 396ms/step - loss: 9.1802 - rmse: 3.0297 - val_loss: 8.3524 - val_rmse: 2.8900\nEpoch 6/10\n\u001b[1m256/256\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m104s\u001b[0m 395ms/step - loss: 9.4944 - rmse: 3.0803 - val_loss: 7.4779 - val_rmse: 2.7349\nEpoch 7/10\n\u001b[1m256/256\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m104s\u001b[0m 395ms/step - loss: 9.3007 - rmse: 3.0468 - val_loss: 7.9487 - val_rmse: 2.8191\nEpoch 8/10\n\u001b[1m256/256\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m104s\u001b[0m 395ms/step - loss: 8.7159 - rmse: 2.9492 - val_loss: 7.7942 - val_rmse: 2.7917\nEpoch 9/10\n\u001b[1m256/256\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m104s\u001b[0m 395ms/step - loss: 7.8985 - rmse: 2.8085 - val_loss: 7.5763 - val_rmse: 2.7525\nEpoch 10/10\n\u001b[1m256/256\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m105s\u001b[0m 400ms/step - loss: 9.0738 - rmse: 3.0043 - val_loss: 7.8627 - val_rmse: 2.8039\n","output_type":"stream"}]},{"cell_type":"code","source":"test_df = pd.read_csv('/kaggle/input/vista-codefest-1/dataset/test.csv')\n\ntest_datagen = ImageDataGenerator(rescale=1./255)\n\ntest_generator = test_datagen.flow_from_dataframe(\n    dataframe=test_df,\n    directory='/kaggle/working/dataset/preprocessed/test',\n    x_col='Name',\n    y_col=None,\n    target_size=(224, 224),\n    batch_size=32,\n    class_mode=None,\n    shuffle=False  # Important for maintaining order\n)\n\npredictions = model.predict(test_generator)\n\n\n# Round the predictions to the nearest integer\npredicted_head_counts = predictions.flatten()\n\n# Create a DataFrame for the submission\nsubmission_df = pd.DataFrame({\n    'Name': test_df['Name'],\n    'HeadCount': predicted_head_counts\n})\n\n# Save the submission DataFrame to a CSV file\nsubmission_df.to_csv('/kaggle/working/submission_main_vgg_kaggle.csv', index=False)\n","metadata":{"execution":{"iopub.status.busy":"2024-03-29T17:05:52.575367Z","iopub.execute_input":"2024-03-29T17:05:52.576185Z","iopub.status.idle":"2024-03-29T17:06:13.166115Z","shell.execute_reply.started":"2024-03-29T17:05:52.576153Z","shell.execute_reply":"2024-03-29T17:06:13.165338Z"},"trusted":true},"execution_count":46,"outputs":[{"name":"stdout","text":"Found 3963 validated image filenames.\n","output_type":"stream"},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:122: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n  self._warn_if_super_not_called()\n","output_type":"stream"},{"name":"stdout","text":"\u001b[1m123/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 60ms/step","output_type":"stream"},{"name":"stderr","text":"2024-03-29 17:06:01.719372: E external/local_xla/xla/service/gpu/buffer_comparator.cc:1137] Difference at 0: 3.99165, expected 3.3217\n2024-03-29 17:06:01.719429: E external/local_xla/xla/service/gpu/buffer_comparator.cc:1137] Difference at 7: 5.28926, expected 4.61931\n2024-03-29 17:06:01.719439: E external/local_xla/xla/service/gpu/buffer_comparator.cc:1137] Difference at 8: 5.06719, expected 4.39724\n2024-03-29 17:06:01.719447: E external/local_xla/xla/service/gpu/buffer_comparator.cc:1137] Difference at 11: 5.46955, expected 4.7996\n2024-03-29 17:06:01.719454: E external/local_xla/xla/service/gpu/buffer_comparator.cc:1137] Difference at 12: 3.74731, expected 3.07735\n2024-03-29 17:06:01.719462: E external/local_xla/xla/service/gpu/buffer_comparator.cc:1137] Difference at 13: 3.78108, expected 3.11113\n2024-03-29 17:06:01.719469: E external/local_xla/xla/service/gpu/buffer_comparator.cc:1137] Difference at 14: 5.36791, expected 4.69796\n2024-03-29 17:06:01.719477: E external/local_xla/xla/service/gpu/buffer_comparator.cc:1137] Difference at 28: 5.61502, expected 4.94507\n2024-03-29 17:06:01.719484: E external/local_xla/xla/service/gpu/buffer_comparator.cc:1137] Difference at 29: 4.43438, expected 3.76443\n2024-03-29 17:06:01.719492: E external/local_xla/xla/service/gpu/buffer_comparator.cc:1137] Difference at 30: 4.30893, expected 3.63898\n2024-03-29 17:06:01.758927: E external/local_xla/xla/service/gpu/conv_algorithm_picker.cc:705] Results mismatch between different convolution algorithms. This is likely a bug/unexpected loss of precision in cudnn.\n(f32[27,64,224,224]{3,2,1,0}, u8[0]{0}) custom-call(f32[27,3,224,224]{3,2,1,0}, f32[64,3,3,3]{3,2,1,0}, f32[64]{0}), window={size=3x3 pad=1_1x1_1}, dim_labels=bf01_oi01->bf01, custom_call_target=\"__cudnn$convBiasActivationForward\", backend_config={\"conv_result_scale\":1,\"activation_mode\":\"kRelu\",\"side_input_scale\":0,\"leakyrelu_alpha\":0} for eng20{k2=1,k4=1,k5=1,k6=0,k7=0} vs eng15{k5=1,k6=0,k7=1,k10=1}\n2024-03-29 17:06:01.758972: E external/local_xla/xla/service/gpu/conv_algorithm_picker.cc:270] Device: Tesla P100-PCIE-16GB\n2024-03-29 17:06:01.758981: E external/local_xla/xla/service/gpu/conv_algorithm_picker.cc:271] Platform: Compute Capability 6.0\n2024-03-29 17:06:01.758988: E external/local_xla/xla/service/gpu/conv_algorithm_picker.cc:272] Driver: 12020 (535.129.3)\n2024-03-29 17:06:01.758995: E external/local_xla/xla/service/gpu/conv_algorithm_picker.cc:273] Runtime: <undefined>\n2024-03-29 17:06:01.759012: E external/local_xla/xla/service/gpu/conv_algorithm_picker.cc:280] cudnn version: 8.9.0\n2024-03-29 17:06:02.605853: E external/local_xla/xla/service/gpu/buffer_comparator.cc:1137] Difference at 0: 3.99165, expected 3.3217\n2024-03-29 17:06:02.605916: E external/local_xla/xla/service/gpu/buffer_comparator.cc:1137] Difference at 7: 5.28926, expected 4.61931\n2024-03-29 17:06:02.605926: E external/local_xla/xla/service/gpu/buffer_comparator.cc:1137] Difference at 8: 5.06719, expected 4.39724\n2024-03-29 17:06:02.605934: E external/local_xla/xla/service/gpu/buffer_comparator.cc:1137] Difference at 11: 5.46955, expected 4.7996\n2024-03-29 17:06:02.605942: E external/local_xla/xla/service/gpu/buffer_comparator.cc:1137] Difference at 12: 3.74731, expected 3.07735\n2024-03-29 17:06:02.605950: E external/local_xla/xla/service/gpu/buffer_comparator.cc:1137] Difference at 13: 3.78108, expected 3.11113\n2024-03-29 17:06:02.605958: E external/local_xla/xla/service/gpu/buffer_comparator.cc:1137] Difference at 14: 5.36791, expected 4.69796\n2024-03-29 17:06:02.605966: E external/local_xla/xla/service/gpu/buffer_comparator.cc:1137] Difference at 28: 5.61502, expected 4.94507\n2024-03-29 17:06:02.605974: E external/local_xla/xla/service/gpu/buffer_comparator.cc:1137] Difference at 29: 4.43438, expected 3.76443\n2024-03-29 17:06:02.605982: E external/local_xla/xla/service/gpu/buffer_comparator.cc:1137] Difference at 30: 4.30893, expected 3.63898\n2024-03-29 17:06:02.644748: E external/local_xla/xla/service/gpu/conv_algorithm_picker.cc:705] Results mismatch between different convolution algorithms. This is likely a bug/unexpected loss of precision in cudnn.\n(f32[27,64,224,224]{3,2,1,0}, u8[0]{0}) custom-call(f32[27,3,224,224]{3,2,1,0}, f32[64,3,3,3]{3,2,1,0}, f32[64]{0}), window={size=3x3 pad=1_1x1_1}, dim_labels=bf01_oi01->bf01, custom_call_target=\"__cudnn$convBiasActivationForward\", backend_config={\"conv_result_scale\":1,\"activation_mode\":\"kRelu\",\"side_input_scale\":0,\"leakyrelu_alpha\":0} for eng20{k2=1,k4=1,k5=1,k6=0,k7=0} vs eng15{k5=1,k6=0,k7=1,k10=1}\n2024-03-29 17:06:02.644784: E external/local_xla/xla/service/gpu/conv_algorithm_picker.cc:270] Device: Tesla P100-PCIE-16GB\n2024-03-29 17:06:02.644793: E external/local_xla/xla/service/gpu/conv_algorithm_picker.cc:271] Platform: Compute Capability 6.0\n2024-03-29 17:06:02.644799: E external/local_xla/xla/service/gpu/conv_algorithm_picker.cc:272] Driver: 12020 (535.129.3)\n2024-03-29 17:06:02.644806: E external/local_xla/xla/service/gpu/conv_algorithm_picker.cc:273] Runtime: <undefined>\n2024-03-29 17:06:02.644822: E external/local_xla/xla/service/gpu/conv_algorithm_picker.cc:280] cudnn version: 8.9.0\n","output_type":"stream"},{"name":"stdout","text":"\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 160ms/step\n","output_type":"stream"}]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#advanced model","metadata":{"execution":{"iopub.status.busy":"2024-03-29T17:09:50.492243Z","iopub.execute_input":"2024-03-29T17:09:50.492612Z","iopub.status.idle":"2024-03-29T17:09:50.496726Z","shell.execute_reply.started":"2024-03-29T17:09:50.492584Z","shell.execute_reply":"2024-03-29T17:09:50.495770Z"},"trusted":true},"execution_count":47,"outputs":[]},{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport tensorflow as tf  # Add this line to import TensorFlow\nfrom sklearn.model_selection import train_test_split\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\nfrom tensorflow.keras.applications import VGG16, ResNet50\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Flatten, Dense, Dropout\nfrom tensorflow.keras.optimizers import Adam\n","metadata":{"execution":{"iopub.status.busy":"2024-03-29T17:10:54.682819Z","iopub.execute_input":"2024-03-29T17:10:54.683521Z","iopub.status.idle":"2024-03-29T17:10:54.689051Z","shell.execute_reply.started":"2024-03-29T17:10:54.683491Z","shell.execute_reply":"2024-03-29T17:10:54.688086Z"},"trusted":true},"execution_count":48,"outputs":[]},{"cell_type":"code","source":"train_df = pd.read_csv('/kaggle/input/vista-codefest-1/dataset/train.csv')\ntrain_df['HeadCount'] = train_df['HeadCount'].astype('float32')\ntest_df = pd.read_csv('/kaggle/input/vista-codefest-1/dataset/test.csv')\ntest_df['HeadCount'] = test_df['HeadCount'].astype('float32')\n\n# Split the data into training and validation sets\ntrain_data, val_data = train_test_split(train_df, test_size=0.2, random_state=42)\n\n# Set up image data generators with data augmentation\ntrain_datagen = ImageDataGenerator(\n    rescale=1./255,\n    rotation_range=20,\n    width_shift_range=0.2,\n    height_shift_range=0.2,\n    shear_range=0.2,\n    zoom_range=0.2,\n    horizontal_flip=True,\n    fill_mode='nearest'\n)\n\nval_datagen = ImageDataGenerator(rescale=1./255)\n\n# Create data generators\ntrain_generator = train_datagen.flow_from_dataframe(\n    dataframe=train_data,\n    directory='/kaggle/working/dataset/preprocessed/train',\n    x_col='Name',\n    y_col='HeadCount',\n    target_size=(224, 224),\n    batch_size=32,\n    class_mode='raw'\n)\n\nval_generator = val_datagen.flow_from_dataframe(\n    dataframe=val_data,\n    directory='/kaggle/working/dataset/preprocessed/train',\n    x_col='Name',\n    y_col='HeadCount',\n    target_size=(224, 224),\n    batch_size=32,\n    class_mode='raw'\n)\n","metadata":{"execution":{"iopub.status.busy":"2024-03-29T17:13:35.464481Z","iopub.execute_input":"2024-03-29T17:13:35.464837Z","iopub.status.idle":"2024-03-29T17:13:35.593980Z","shell.execute_reply.started":"2024-03-29T17:13:35.464808Z","shell.execute_reply":"2024-03-29T17:13:35.593251Z"},"trusted":true},"execution_count":51,"outputs":[{"name":"stdout","text":"Found 8186 validated image filenames.\nFound 2047 validated image filenames.\n","output_type":"stream"}]},{"cell_type":"code","source":"def create_model(base_model):\n    model = Sequential()\n    model.add(base_model)\n    model.add(Flatten())\n    model.add(Dense(256, activation='relu'))\n    model.add(Dropout(0.5))\n    model.add(Dense(1, activation='linear'))\n    model.compile(optimizer=Adam(learning_rate=1e-4), loss='mse', metrics=[tf.keras.metrics.RootMeanSquaredError(name='rmse')])\n    return model\n\n# VGG16 model\nvgg_base = VGG16(weights='imagenet', include_top=False, input_shape=(224, 224, 3))\nvgg_model = create_model(vgg_base)\nvgg_model.fit(train_generator, epochs=10, validation_data=val_generator)\n\n# ResNet50 model\nresnet_base = ResNet50(weights='imagenet', include_top=False, input_shape=(224, 224, 3))\nresnet_model = create_model(resnet_base)\nresnet_model.fit(train_generator, epochs=10, validation_data=val_generator)\n","metadata":{"execution":{"iopub.status.busy":"2024-03-29T17:13:38.605187Z","iopub.execute_input":"2024-03-29T17:13:38.605802Z","iopub.status.idle":"2024-03-29T17:51:07.924057Z","shell.execute_reply.started":"2024-03-29T17:13:38.605770Z","shell.execute_reply":"2024-03-29T17:51:07.923096Z"},"trusted":true},"execution_count":52,"outputs":[{"name":"stdout","text":"Epoch 1/10\n","output_type":"stream"},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:122: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n  self._warn_if_super_not_called()\n","output_type":"stream"},{"name":"stdout","text":"\u001b[1m256/256\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m149s\u001b[0m 475ms/step - loss: 15.9826 - rmse: 3.9875 - val_loss: 9.9747 - val_rmse: 3.1579\nEpoch 2/10\n\u001b[1m256/256\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m106s\u001b[0m 403ms/step - loss: 11.4248 - rmse: 3.3778 - val_loss: 8.6463 - val_rmse: 2.9401\nEpoch 3/10\n\u001b[1m256/256\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m108s\u001b[0m 410ms/step - loss: 12.5434 - rmse: 3.5346 - val_loss: 7.8493 - val_rmse: 2.8018\nEpoch 4/10\n\u001b[1m256/256\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m106s\u001b[0m 402ms/step - loss: 10.1409 - rmse: 3.1830 - val_loss: 7.5533 - val_rmse: 2.7480\nEpoch 5/10\n\u001b[1m256/256\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m106s\u001b[0m 402ms/step - loss: 10.2060 - rmse: 3.1926 - val_loss: 7.5420 - val_rmse: 2.7465\nEpoch 6/10\n\u001b[1m256/256\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m106s\u001b[0m 401ms/step - loss: 9.4135 - rmse: 3.0669 - val_loss: 6.9363 - val_rmse: 2.6337\nEpoch 7/10\n\u001b[1m256/256\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m106s\u001b[0m 403ms/step - loss: 8.6332 - rmse: 2.9379 - val_loss: 12.5294 - val_rmse: 3.5398\nEpoch 8/10\n\u001b[1m256/256\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m106s\u001b[0m 403ms/step - loss: 10.2107 - rmse: 3.1898 - val_loss: 10.7891 - val_rmse: 3.2843\nEpoch 9/10\n\u001b[1m256/256\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m106s\u001b[0m 402ms/step - loss: 9.6589 - rmse: 3.1059 - val_loss: 9.5289 - val_rmse: 3.0872\nEpoch 10/10\n\u001b[1m256/256\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m105s\u001b[0m 401ms/step - loss: 8.9189 - rmse: 2.9843 - val_loss: 9.2361 - val_rmse: 3.0393\nEpoch 1/10\n\u001b[1m256/256\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m195s\u001b[0m 529ms/step - loss: 37.8670 - rmse: 5.8094 - val_loss: 68.3896 - val_rmse: 8.2697\nEpoch 2/10\n\u001b[1m256/256\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m105s\u001b[0m 399ms/step - loss: 13.5409 - rmse: 3.6776 - val_loss: 19.6166 - val_rmse: 4.4294\nEpoch 3/10\n\u001b[1m256/256\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m105s\u001b[0m 399ms/step - loss: 12.2027 - rmse: 3.4925 - val_loss: 14.1866 - val_rmse: 3.7665\nEpoch 4/10\n\u001b[1m256/256\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m107s\u001b[0m 405ms/step - loss: 11.2144 - rmse: 3.3479 - val_loss: 10.1355 - val_rmse: 3.1836\nEpoch 5/10\n\u001b[1m256/256\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m105s\u001b[0m 398ms/step - loss: 10.5073 - rmse: 3.2413 - val_loss: 8.1736 - val_rmse: 2.8589\nEpoch 6/10\n\u001b[1m256/256\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m105s\u001b[0m 401ms/step - loss: 11.6060 - rmse: 3.4055 - val_loss: 7.6584 - val_rmse: 2.7676\nEpoch 7/10\n\u001b[1m256/256\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m105s\u001b[0m 399ms/step - loss: 10.0767 - rmse: 3.1724 - val_loss: 6.3109 - val_rmse: 2.5119\nEpoch 8/10\n\u001b[1m256/256\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m105s\u001b[0m 397ms/step - loss: 9.6301 - rmse: 3.1019 - val_loss: 9.1546 - val_rmse: 3.0249\nEpoch 9/10\n\u001b[1m256/256\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m106s\u001b[0m 404ms/step - loss: 9.9344 - rmse: 3.1514 - val_loss: 6.6767 - val_rmse: 2.5843\nEpoch 10/10\n\u001b[1m256/256\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m105s\u001b[0m 398ms/step - loss: 9.7643 - rmse: 3.1230 - val_loss: 7.6366 - val_rmse: 2.7637\n","output_type":"stream"},{"execution_count":52,"output_type":"execute_result","data":{"text/plain":"<keras.src.callbacks.history.History at 0x7d66cb1e8dc0>"},"metadata":{}}]},{"cell_type":"code","source":"# Prepare the test data generator\ntest_datagen = ImageDataGenerator(rescale=1./255)\ntest_generator = test_datagen.flow_from_dataframe(\n    dataframe=test_df,\n    directory='/kaggle/working/dataset/preprocessed/test',\n    x_col='Name',\n    y_col=None,\n    target_size=(224, 224),\n    batch_size=32,\n    class_mode=None,\n    shuffle=False\n)\n\n# Make predictions with both models\nvgg_predictions = vgg_model.predict(test_generator)\n\n# Create a submission DataFrame\nsubmission_df = pd.DataFrame({\n    'Name': test_df['Name'],\n    'HeadCount': vgg_predictions.flatten()\n})\n\n# Save the submission DataFrame to a CSV file\nsubmission_df.to_csv('/kaggle/working/submission2_vgg_kaggle_main.csv', index=False)\n\nresnet_predictions = resnet_model.predict(test_generator)\n\n# Create a submission DataFrame\nsubmission_df = pd.DataFrame({\n    'Name': test_df['Name'],\n    'HeadCount': resnet_predictions.flatten()\n})\n\n# Save the submission DataFrame to a CSV file\nsubmission_df.to_csv('/kaggle/working/submission2_resnet_kaggle_main.csv', index=False)\n\n# Average the predictions\nfinal_predictions = (vgg_predictions.flatten() + resnet_predictions.flatten()) / 2\n\n# Round the predictions to the nearest integer\nfinal_head_counts = final_predictions\n\n# Create a submission DataFrame\nsubmission_df = pd.DataFrame({\n    'Name': test_df['Name'],\n    'HeadCount': final_head_counts\n})\n\n# Save the submission DataFrame to a CSV file\nsubmission_df.to_csv('/kaggle/working/submission2_kaggle.csv', index=False)\n","metadata":{"execution":{"iopub.status.busy":"2024-03-29T17:51:07.925977Z","iopub.execute_input":"2024-03-29T17:51:07.926363Z","iopub.status.idle":"2024-03-29T17:51:29.177610Z","shell.execute_reply.started":"2024-03-29T17:51:07.926313Z","shell.execute_reply":"2024-03-29T17:51:29.176666Z"},"trusted":true},"execution_count":53,"outputs":[{"name":"stdout","text":"Found 3963 validated image filenames.\n\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 64ms/step\n\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 71ms/step\n","output_type":"stream"}]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}