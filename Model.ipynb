{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2878fa15-c6f4-4897-9882-58f6f6a80cf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.applications import VGG16\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Flatten, Dense\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "56d4f7ea-cfc3-45dc-93df-2c60978c9920",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 8186 validated image filenames.\n",
      "Found 2047 validated image filenames.\n"
     ]
    }
   ],
   "source": [
    "# Load the preprocessed data\n",
    "train_df = pd.read_csv('dataset/train.csv')\n",
    "\n",
    "# Split the data into training and validation sets\n",
    "train_data, val_data = train_test_split(train_df, test_size=0.2, random_state=42)\n",
    "\n",
    "# Set up image data generators\n",
    "train_datagen = ImageDataGenerator(rescale=1./255)\n",
    "val_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "train_generator = train_datagen.flow_from_dataframe(\n",
    "    dataframe=train_data,\n",
    "    directory='dataset/preprocessed/train',\n",
    "    x_col='Name',\n",
    "    y_col='HeadCount',\n",
    "    target_size=(224, 224),\n",
    "    batch_size=32,\n",
    "    class_mode='raw'\n",
    ")\n",
    "\n",
    "val_generator = val_datagen.flow_from_dataframe(\n",
    "    dataframe=val_data,\n",
    "    directory='dataset/preprocessed/train',\n",
    "    x_col='Name',\n",
    "    y_col='HeadCount',\n",
    "    target_size=(224, 224),\n",
    "    batch_size=32,\n",
    "    class_mode='raw'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8f4f589b-7931-4dd4-aed0-3e1cba8718b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/vgg16/vgg16_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
      "58889256/58889256 [==============================] - 4s 0us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
     ]
    }
   ],
   "source": [
    "# Load a pre-trained VGG16 model without the top layer\n",
    "base_model = VGG16(weights='imagenet', include_top=False, input_shape=(224, 224, 3))\n",
    "\n",
    "# Freeze the base model layers\n",
    "for layer in base_model.layers:\n",
    "    layer.trainable = False\n",
    "\n",
    "# Create a sequential model and add the base model\n",
    "model = Sequential()\n",
    "model.add(base_model)\n",
    "model.add(Flatten())\n",
    "model.add(Dense(256, activation='relu'))\n",
    "model.add(Dense(1, activation='linear'))  # Output layer for regression\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer=Adam(lr=1e-4), loss='mse', metrics=[tf.keras.metrics.RootMeanSquaredError(name='rmse')])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0084cb25-702d-4a29-83b3-58b4b5c1213f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "256/256 [==============================] - 698s 3s/step - loss: 15.3474 - rmse: 3.9176 - val_loss: 7.6915 - val_rmse: 2.7733\n",
      "Epoch 2/10\n",
      "256/256 [==============================] - 575s 2s/step - loss: 7.8872 - rmse: 2.8084 - val_loss: 6.9850 - val_rmse: 2.6429\n",
      "Epoch 3/10\n",
      "256/256 [==============================] - 556s 2s/step - loss: 6.8237 - rmse: 2.6122 - val_loss: 7.1540 - val_rmse: 2.6747\n",
      "Epoch 4/10\n",
      "256/256 [==============================] - 566s 2s/step - loss: 6.2056 - rmse: 2.4911 - val_loss: 6.5655 - val_rmse: 2.5623\n",
      "Epoch 5/10\n",
      "256/256 [==============================] - 561s 2s/step - loss: 5.8618 - rmse: 2.4211 - val_loss: 6.5505 - val_rmse: 2.5594\n",
      "Epoch 6/10\n",
      "256/256 [==============================] - 566s 2s/step - loss: 5.4407 - rmse: 2.3325 - val_loss: 7.3436 - val_rmse: 2.7099\n",
      "Epoch 7/10\n",
      "256/256 [==============================] - 557s 2s/step - loss: 5.1025 - rmse: 2.2589 - val_loss: 7.6063 - val_rmse: 2.7580\n",
      "Epoch 8/10\n",
      "256/256 [==============================] - 535s 2s/step - loss: 4.9238 - rmse: 2.2190 - val_loss: 6.2610 - val_rmse: 2.5022\n",
      "Epoch 9/10\n",
      "256/256 [==============================] - 536s 2s/step - loss: 4.6810 - rmse: 2.1636 - val_loss: 6.3102 - val_rmse: 2.5120\n",
      "Epoch 10/10\n",
      "256/256 [==============================] - 533s 2s/step - loss: 4.6373 - rmse: 2.1534 - val_loss: 6.2614 - val_rmse: 2.5023\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(\n",
    "    train_generator,\n",
    "    epochs=10,\n",
    "    validation_data=val_generator\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "15613b68-b6d8-4754-952f-8d1844d744c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('models/head_count_model.keras')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "fb8548ca-d474-4f00-909f-3700b10cd3d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import load_model\n",
    "\n",
    "loaded_model = load_model('models/head_count_model.keras')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4986e2d2-3cc3-4efe-8fd7-b0ee6343de41",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "256/256 [==============================] - 555s 2s/step - loss: 4.2977 - rmse: 2.0731\n",
      "Training Loss: 4.297650337219238\n",
      "Training RMSE: 2.073077440261841\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the model on the training data\n",
    "train_loss, train_rmse = model.evaluate(train_generator)\n",
    "\n",
    "print(f\"Training Loss: {train_loss}\")\n",
    "print(f\"Training RMSE: {train_rmse}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e7d29299-a931-4fd5-b4bd-a8eb3c28a9f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 3963 validated image filenames.\n"
     ]
    }
   ],
   "source": [
    "test_df = pd.read_csv('dataset/test.csv')\n",
    "\n",
    "test_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "test_generator = test_datagen.flow_from_dataframe(\n",
    "    dataframe=test_df,\n",
    "    directory='dataset/preprocessed/test',\n",
    "    x_col='Name',\n",
    "    y_col=None,\n",
    "    target_size=(224, 224),\n",
    "    batch_size=32,\n",
    "    class_mode=None,\n",
    "    shuffle=False  # Important for maintaining order\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b6a79a81-a75c-491d-8231-302a0fb5ca90",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "124/124 [==============================] - 266s 2s/step\n"
     ]
    }
   ],
   "source": [
    "predictions = model.predict(test_generator)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "3fbb8bd9-1c82-4723-8c35-0f8d140dead0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Round the predictions to the nearest integer\n",
    "predicted_head_counts = np.round(predictions.flatten()).astype(int)\n",
    "\n",
    "# Create a DataFrame for the submission\n",
    "submission_df = pd.DataFrame({\n",
    "    'Name': test_df['Name'],\n",
    "    'HeadCount': predicted_head_counts\n",
    "})\n",
    "\n",
    "# Save the submission DataFrame to a CSV file\n",
    "submission_df.to_csv('submission_main.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "fd64ae5e-0de4-43dc-81d8-9f09f6266b18",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([5, 5, 6, ..., 3, 4, 5])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predicted_head_counts\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "d1dc4d8a-7bd5-4293-bc75-048354f0222b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 8186 validated image filenames.\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "# Define the data augmentation for the training data\n",
    "train_datagen = ImageDataGenerator(\n",
    "    rescale=1./255,\n",
    "    rotation_range=20,\n",
    "    width_shift_range=0.2,\n",
    "    height_shift_range=0.2,\n",
    "    shear_range=0.2,\n",
    "    zoom_range=0.2,\n",
    "    horizontal_flip=True,\n",
    "    fill_mode='nearest'\n",
    ")\n",
    "\n",
    "# Create the data generator for the training set\n",
    "train_generator = train_datagen.flow_from_dataframe(\n",
    "    dataframe=train_data,\n",
    "    directory='dataset/preprocessed/train',\n",
    "    x_col='Name',\n",
    "    y_col='HeadCount',\n",
    "    target_size=(224, 224),\n",
    "    batch_size=32,\n",
    "    class_mode='raw'\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "f2c52f38-e940-471b-b5b2-5b95191179d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 8186 validated image filenames.\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "# Define the data augmentation for the training data\n",
    "train_datagen = ImageDataGenerator(\n",
    "    rescale=1./255,\n",
    "    rotation_range=20,\n",
    "    width_shift_range=0.2,\n",
    "    height_shift_range=0.2,\n",
    "    shear_range=0.2,\n",
    "    zoom_range=0.2,\n",
    "    horizontal_flip=True,\n",
    "    fill_mode='nearest'\n",
    ")\n",
    "\n",
    "# Create the data generator for the training set\n",
    "train_generator = train_datagen.flow_from_dataframe(\n",
    "    dataframe=train_data,\n",
    "    directory='dataset/preprocessed/train',\n",
    "    x_col='Name',\n",
    "    y_col='HeadCount',\n",
    "    target_size=(224, 224),\n",
    "    batch_size=32,\n",
    "    class_mode='raw'\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "acbf2601-23b3-4e77-8f74-0036433c1ad2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.applications import ResNet50\n",
    "from tensorflow.keras.layers import Dropout\n",
    "\n",
    "# Load the ResNet50 base model\n",
    "base_model2 = ResNet50(weights='imagenet', include_top=False, input_shape=(224, 224, 3))\n",
    "\n",
    "# Create the model\n",
    "model = Sequential()\n",
    "model.add(base_model)\n",
    "model.add(Flatten())\n",
    "model.add(Dense(256, activation='relu'))\n",
    "model.add(Dropout(0.5))  # Add dropout layer\n",
    "model.add(Dense(1, activation='linear'))\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer=Adam(lr=1e-4), loss='mse', metrics=[tf.keras.metrics.RootMeanSquaredError(name='rmse')])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "d793c479-4405-441e-a37e-7ff7ac38af91",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_image(image_path, size=(224, 224)):\n",
    "    image = cv2.imread(image_path)\n",
    "    image = cv2.resize(image, size)\n",
    "\n",
    "    # Apply histogram equalization\n",
    "    img_yuv = cv2.cvtColor(image, cv2.COLOR_BGR2YUV)\n",
    "    img_yuv[:, :, 0] = cv2.equalizeHist(img_yuv[:, :, 0])\n",
    "    image = cv2.cvtColor(img_yuv, cv2.COLOR_YUV2BGR)\n",
    "\n",
    "    image = image / 255.0  # Normalize pixel values\n",
    "    return image\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "0858cf8e-4fa7-4fa4-9f22-7e498bac650e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "124/124 [==============================] - 132s 1s/step\n",
      "124/124 [==============================] - 131s 1s/step\n"
     ]
    }
   ],
   "source": [
    "# Assume model1 and model2 are two trained models\n",
    "\n",
    "predictions1 = base_model.predict(test_generator)\n",
    "predictions2 = base_model2.predict(test_generator)\n",
    "\n",
    "# Simple averaging ensemble\n",
    "final_predictions = (predictions1.flatten() + predictions2.flatten()) / 2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5e3a47c0-8de6-43a3-aa4a-ace9c275a6e1",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'predictions1' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[3], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mpredictions1\u001b[49m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'predictions1' is not defined"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38a56205-cb04-464f-b320-eb75b827be8a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
